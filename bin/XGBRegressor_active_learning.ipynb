{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933e2761-e3d5-4256-bb3a-cf513964bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем нужные библиотеки\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split # класс разбиения на данные для обучения и для проверки\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "# импортируем функции\n",
    "from functions import generate_random_array, plot_true_vs_predicted,  Functions, Generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715adab1-5277-4a78-9b29-932e5faba912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исходные данные\n",
    "# создаем объект класса Functions \n",
    "main_function = Functions()\n",
    "\n",
    "\n",
    "# определяем количетсво строк для обучения\n",
    "main_function.n_samples = 27\n",
    "\n",
    "# пределы варьирования признаков\n",
    "main_function.limits = (-10, 10)\n",
    "\n",
    "# определяем вид функции\n",
    "main_function.set_function(main_function.ackley)\n",
    "\n",
    "# признаки переопределим с помощью ПФЭ\n",
    "data_generator = Generate_data(main_function.n_samples, main_function.n_features, main_function.limits[0], \n",
    "                               main_function.limits[1], seed = main_function.random_seed)\n",
    "main_function.features = data_generator.generate_latin_hypercube()\n",
    "\n",
    "main_function.target = main_function.function(*main_function.features.T)\n",
    "main_function.n_samples = data_generator.n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9dd890-95ce-4a92-9946-25f4363e8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация пула кандидатов (случайные точки в допустимом диапазоне)\n",
    "rng = np.random.default_rng(seed=12345)\n",
    "X_pool = rng.uniform(low=main_function.limits[0], high=main_function.limits[1], size=(100000, main_function.n_features))\n",
    "y_pool = main_function.function(*X_pool.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5967560a-8280-424f-a284-993d2dfff04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Следующая точка для замера - точка # 52676\n",
      "Ее неопределенность равна: 0.56135\n",
      "Ее расстояние до ближайшей исвестной точки:  6.41791\n",
      "Ее обобщенный показатель: 0.59350\n",
      "Необходимо добавить в массив признаков следующие данные: [-1.00650464 -5.70626128  2.17526106]\n",
      "Значение целевой функции для данной точки будет: 11.449115712688918\n",
      "Макс. неопределённость: 0.65088516\n",
      "Средняя неопределённость: 0.2275184\n",
      "Медиана: 0.21059948\n",
      "Количество точек с uncertainty > 90%-квантиля: 9995\n"
     ]
    }
   ],
   "source": [
    "# Попробуем определить точку, которую желательно добавить в массив для обучения\n",
    "# Обучаем ансамбль из N моделей\n",
    "n_models = 10\n",
    "predictions = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    model = XGBRegressor(\n",
    "                    n_estimators=1000,\n",
    "                    max_depth=3,\n",
    "                    learning_rate=0.1,\n",
    "                    reg_alpha=0.5,\n",
    "                    reg_lambda=0.5,\n",
    "                    subsample=0.8,\n",
    "                    random_state=1488+i,\n",
    "                    verbosity=0\n",
    "                    )\n",
    "    model.fit(main_function.features, main_function.target)\n",
    "    pred = model.predict(X_pool)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Считаем дисперсию предсказаний по ансамблю\n",
    "predictions = np.array(predictions)  # (n_models, n_pool)\n",
    "# Среднеквадратичное отклонение\n",
    "uncertainty = predictions.std(axis=0)  # (n_pool,)\n",
    "# Расстояние до ближайшей известной точки\n",
    "distances = cdist(X_pool, main_function.features).min(axis=1)\n",
    "# Нормализуем оба показателя\n",
    "unc_norm = uncertainty / (uncertainty.max() + 1e-9)\n",
    "dist_norm = distances / (distances.max() + 1e-9)\n",
    "# Считаем обобщенный показатель\n",
    "score = unc_norm * dist_norm\n",
    "\n",
    "\n",
    "\n",
    "# Выбираем точку с максимальной неопределённостью\n",
    "best_idx = np.argmax(score)\n",
    "features_to_add = X_pool[best_idx]\n",
    "# Определяем значение целевой переменной при данных знаениях признаков\n",
    "target_to_add = main_function.function(*features_to_add.T)\n",
    "\n",
    "\n",
    "print(f'Следующая точка для замера - точка # {best_idx}')\n",
    "print (f'Ее неопределенность равна: {uncertainty[best_idx]:.5f}')\n",
    "print (f'Ее расстояние до ближайшей исвестной точки:  {distances[best_idx]:.5f}')\n",
    "print (f'Ее обобщенный показатель: {score[best_idx]:.5f}')\n",
    "print (f'Необходимо добавить в массив признаков следующие данные: {features_to_add}')\n",
    "print (f'Значение целевой функции для данной точки будет: {target_to_add}')\n",
    "print(\"Макс. неопределённость:\", uncertainty.max())\n",
    "print(\"Средняя неопределённость:\", uncertainty.mean())\n",
    "print(\"Медиана:\", np.median(uncertainty))\n",
    "print(\"Количество точек с uncertainty > 90%-квантиля:\", np.sum(uncertainty > np.percentile(uncertainty, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e3533bf-a127-4983-9e3f-822ecd5f3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = len(main_function.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa680395-f337-4447-88da-c3ad383cd06c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_models):\n\u001b[1;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m XGBRegressor(\n\u001b[1;32m     13\u001b[0m                     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     14\u001b[0m                     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m                     )\n\u001b[0;32m---> 22\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(main_function\u001b[38;5;241m.\u001b[39mfeatures, main_function\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m     23\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_pool)\n\u001b[1;32m     24\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1248\u001b[0m     params,\n\u001b[1;32m   1249\u001b[0m     train_dmatrix,\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1251\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[1;32m   1252\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1253\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[1;32m   1254\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1255\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   1256\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1257\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1258\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   1259\u001b[0m )\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2246\u001b[0m     _check_call(\n\u001b[0;32m-> 2247\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[1;32m   2248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   2249\u001b[0m         )\n\u001b[1;32m   2250\u001b[0m     )\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while j <= 150:\n",
    "    #Добавляем в признаки\n",
    "    main_function.features = np.vstack([main_function.features,features_to_add.reshape(1, -1)])\n",
    "\n",
    "    #Добавляем в целевую переменную\n",
    "    main_function.target = np.append(main_function.target, target_to_add)\n",
    "\n",
    "    n_models = 10\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        model = XGBRegressor(\n",
    "                        n_estimators=1000,\n",
    "                        max_depth=3,\n",
    "                        learning_rate=0.1,\n",
    "                        reg_alpha=0.5,\n",
    "                        reg_lambda=0.5,\n",
    "                        subsample=0.8,\n",
    "                        random_state=1488+i,\n",
    "                        verbosity=0\n",
    "                        )\n",
    "        model.fit(main_function.features, main_function.target)\n",
    "        pred = model.predict(X_pool)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Считаем дисперсию предсказаний по ансамблю\n",
    "    predictions = np.array(predictions)  # (n_models, n_pool)\n",
    "    # Среднеквадратичное отклонение\n",
    "    uncertainty = predictions.std(axis=0)  # (n_pool,)\n",
    "    # Расстояние до ближайшей известной точки\n",
    "    distances = cdist(X_pool, main_function.features).min(axis=1)\n",
    "    # Нормализуем оба показателя\n",
    "    unc_norm = uncertainty / (uncertainty.max() + 1e-9)\n",
    "    dist_norm = distances / (distances.max() + 1e-9)\n",
    "    # Считаем обобщенный показатель\n",
    "    score = unc_norm * dist_norm\n",
    "    \n",
    "    # Выбираем точку с максимальной неопределённостью\n",
    "    best_idx = np.argmax(score)\n",
    "    features_to_add = X_pool[best_idx]\n",
    "    # Определяем значение целевой переменной при данных знаениях признаков\n",
    "    target_to_add = main_function.function(*features_to_add.T)\n",
    " \n",
    "    \n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fea09-8084-468e-8686-73bd00a2828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на результат\n",
    "y_pred_big_test = model.predict(X_pool) \n",
    "plot_true_vs_predicted (y_pool, y_pred_big_test, title= f'XGBRegressor big test. Function is {main_function.function_name}. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd01ad-e053-4a70-8a05-3f91569b8302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
